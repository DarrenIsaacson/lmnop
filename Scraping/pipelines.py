# -*- coding: utf-8 -*-

# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html

""" The pipeline file. Pipelines take the items generated by the spiders and process them, in this case by adding infomation to the database. """

from datetime import datetime
from lmn.models import Show, Venue, Artist as Artist_Model
from scrapy.crawler import CrawlerProcess
import Scraping.items

class ShowPipeline(object):
    """ The show pipeline ensures that the artist and venue exist in the database, creates them if they are not, and converts the event item into the show model. """
    def process_item(self, item, spider): 
        if isinstance(item, Scraping.items.Venue):
            venue = Venue(name=item['name'], city=item['city'], state=item['state'])
            if not Venue.objects.filter(name=item['name']).exists():
                venue.save()
            return item

        if isinstance(item, Scraping.items.Event):
            artist = Artist_Model(name=item['artist'])
            if not Artist_Model.objects.filter(name=item['artist']).exists():
                artist.save()

            if not Show.objects.filter(url=item['url']).exists():
                date_object = datetime.strptime(item['date'], '%A, %B %d, %Y')

                artist = Artist_Model.objects.get(name=item['artist'])
                venue = Venue.objects.get(name=item['venue'])
                show = Show(artist = artist, venue = venue, name = item['name'], url = item['url'], time = item['time'], ages = item['ages'], show_date = date_object)
                show.save()

        return item

